apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-assets
  labels:
    app: {{ template "..name" . }}
    chart: {{ template "..chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  gen_hostfile.sh: |
    set -xev

    target=$1
    max_try=$2

    trap "rm -f ${target}_new" EXIT TERM INT KILL

    cluster_size=$(kubectl -n {{ .Release.Namespace }} get statefulsets {{ .Release.Name }}-worker -o jsonpath='{.status.replicas}')

    tried=0
    until [ "$(wc -l < ${target}_new)" -eq $cluster_size ]; do
      pod_names=$(kubectl -n {{ .Release.Namespace }} get pod \
        --selector=app={{ template "..name" . }},chart={{ template "..chart" . }},release={{ .Release.Name }},role=worker \
        --field-selector=status.phase=Running \
        -o=jsonpath='{.items[*].metadata.name}')
      #pod_names=$(kubectl -n {{ .Release.Namespace }} get pod \
      #  --selector=app={{ template "..name" . }},chart={{ template "..chart" . }},release={{ .Release.Name }},role=worker \
      #  --field-selector=status.phase=Running \
      #  -o=jsonpath='{.items[*].status.podIP}')

      rm -f ${target}_new
      for p in ${pod_names}; do
        echo "${p}.{{ .Release.Name }}.{{ .Release.Namespace }}.svc.cluster.local" >> ${target}_new
        #echo "${p}" >> ${target}_new
      done

      tried=$(expr $tried + 1)
      if [ -n "$max_try" ] && [ $max_try -ge $tried ]; then
        break
      fi
    done

    #master_name=$(kubectl -n {{ .Release.Namespace }} get pod \
    #  --selector=app={{ template "..name" . }},chart={{ template "..chart" . }},release={{ .Release.Name }},role=master \
    #  --field-selector=status.phase=Running \
    #  -o=jsonpath='{.items[*].status.podIP}')

    sed -i "1i{{ .Release.Name }}-master.{{ .Release.Name }}.{{ .Release.Namespace }}.svc.cluster.local" ${target}_new
    #sed -i "1i${master_name}" ${target}_new

    if [ -e ${target}_new ]; then
      mv ${target}_new ${target}
    fi

{{ if .Values.mpiMaster.autoUpdateHostfile.enabled }}
  hostfile_update_every: {{.Values.mpiMaster.autoUpdateHostfile.updateEvery | default "15" | quote }}
{{ end }}

---
# Source: kube-openmpi/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-ceph-config
  labels:
    app: {{ template "..name" . }}
    chart: {{ template "..chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  ceph.conf: |
    [global]
    keyring = /etc/ceph/ceph.client.kubernetes.keyring
    fsid = f94678af-d10a-4f10-a6cd-7eb429bc1847
    mon_initial_members = mon1
    mon_host = 10.4.99.101
    auth_cluster_required = cephx
    auth_service_required = cephx
    auth_client_required = cephx
    public_network = 10.4.99.0/16
    cluster_network = 10.5.99.0/16
    osd_crush_chooseleaf_type = 1

    [mon.0]
    host = mon1
    mon_addr = 10.4.99.101

    [osd.0]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.1]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.2]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.3]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.4]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.5]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.6]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.7]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.8]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.9]
    host = osd1
    public_addr = 10.4.99.102
    cluster_addr = 10.5.99.102

    [osd.10]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.11]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.12]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.13]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.14]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.15]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.16]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.17]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.18]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.19]
    host = osd2
    public_addr = 10.4.99.103
    cluster_addr = 10.5.99.103

    [osd.20]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.21]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.22]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.23]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.24]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.25]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.26]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.27]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.28]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104

    [osd.29]
    host = osd3
    public_addr = 10.4.99.104
    cluster_addr = 10.5.99.104


    [client]
    name = client.kubernetes
    client quota = true
    mon host = 10.4.99.102:6789,10.4.99.101:6789,10.4.99.100:6789

    [client.kubernetes]
    key = AQA29Y9bm5glMhAA8D1DTGuEsbT/SILH0+eTFg==
